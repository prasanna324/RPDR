{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting encounters.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile encounters.py\n",
    "\n",
    "def load_RPDR_enc_multiple(dir_data, fname, delimiter='|'):\n",
    "    ''' load_RPDR_dem_multiple(dir_data, fname, delimiter='\\t'):\n",
    "        Sequentially loads all files from RPDR data dump when output is split. \n",
    "        \n",
    "        1. Starts in dir_data (should have trailing slash), grabs all sub-folders' names automatically, then sequentially loads: dir_data/[sub-folders]/fname (where fname is the name of the file)\n",
    "        * Note for whatever reason, on a multiple-split file dump from RPDR the labs, demographics, etc files are all named the exact same, just in different zips\n",
    "        2. Calls the traditional load path function on each file\n",
    "        3. Concatenates all results and returns 1 DF\n",
    "        \n",
    "        See load_native_data for remainder of parameters which are passed to that function\n",
    "        \n",
    "        '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    # get list of subdirectories\n",
    "    subdirectories = [x[0] for x in os.walk(dir_data)][1:]\n",
    "    \n",
    "    first=True\n",
    "    # for each subdir, use the traditional load function to load data and concat\n",
    "    for subdir in subdirectories:\n",
    "        path_to_path=subdir+'/'+fname\n",
    "        path = load_RPDR_enc(path_to_path, delimiter=delimiter)\n",
    "        \n",
    "        if first==True:\n",
    "            concat_pd = path\n",
    "            first=False\n",
    "        else:\n",
    "            concat_pd=pd.concat([concat_pd, path],ignore_index=True)\n",
    "    \n",
    "    return concat_pd\n",
    "\n",
    "\n",
    "def load_RPDR_enc(path, delimiter='|'):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import os.path\n",
    "    from os import path as os_path\n",
    "    \n",
    "    path_df = pd.read_csv(path, delimiter=delimiter, dtype=str)\n",
    "    path_df['Admit_Date'] = pd.to_datetime(path_df['Admit_Date'], errors='ignore')\n",
    "    path_df['Discharge_Date'] = pd.to_datetime(path_df['Discharge_Date'], errors='ignore')\n",
    "    \n",
    "    path_df.loc[path_df['Discharge_Date']<'1900','Discharge_Date'] = None\n",
    "    \n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
