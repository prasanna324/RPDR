{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting endoscopy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile endoscopy.py\n",
    "\n",
    "def load_RPDR_endo(path,delimiter='|', datetime_col='Report_Date_Time'):\n",
    "    ''' load_RPDR_endo(path, delimiter='|', datetime_col='Report_Date_Time'):\n",
    "        Loads RPDR endoscopy notes file as pandas dataframe\n",
    "        \n",
    "        PARAMETERS:\n",
    "        path: path to csv file or other text delimited file\n",
    "        delimiter: delimiter for path file\n",
    "        datetime_col: column name containing date/time information for each path report\n",
    "\n",
    "        returns: pandas dataframe containing path information\n",
    "        \n",
    "        WARNINGS:\n",
    "        1. Current function automatically searches for path + 'multiline_corrected', *if present* it assumes that is the correct \n",
    "            file. E.g., path='/data/path.txt', it searches for '/data/path_multiline_corrected.txt'.\n",
    "        2. It will not overwrite this file if present\n",
    "    \n",
    "        '''\n",
    "    import pandas as pd\n",
    "    import os.path\n",
    "    from os import path as os_path\n",
    "    \n",
    "    write_path = path.replace('.','_multiline_corrected.')\n",
    "    if os_path.exists(write_path)==False:\n",
    "        print('Reformatting path file to allow multi-line report text to be readable, saving as : {}'.format(write_path))\n",
    "        \n",
    "        with open(write_path,'w') as file_w:\n",
    "            with open(path) as file_r:\n",
    "                for i in range(1):\n",
    "                    first_line = next(file_r)\n",
    "                    file_w.write(first_line)\n",
    "                for i,line in enumerate(file_r):\n",
    "                    # Replace single quote with double quotes in all the lines\n",
    "                    line = line.replace('\"', '\"\"')\n",
    "                    # Find the right-most occurence of the character \"|\" in a line\n",
    "                    index = line.rfind(\"|\")\n",
    "                    # Number of times \"|\" is present in a line\n",
    "                    count = line.count(\"|\")\n",
    "                    \n",
    "                    if index!=-1 and count==9:\n",
    "                        # Replace the last occurence of '|' with '|\"'\n",
    "                        line = line[:index+1] + '\"' + line[index+1:]\n",
    "                    line = line.replace('[report_end]', '[report_end]\"')\n",
    "                    file_w.write(line)\n",
    "        file_r.close()\n",
    "        file_w.close()\n",
    "        \n",
    "    path = write_path\n",
    "    \n",
    "    # Read the processed .csv file from path location\n",
    "    print('Reading from : ' + path)\n",
    "    path_df = pd.read_csv(path, sep=delimiter, dtype=str)\n",
    "    \n",
    "    # Create unique_report_id by joining EMPI and Report_Number\n",
    "    path_df['unique_report_id'] = path_df.apply(lambda x: str(x.EMPI) + '_' + str(x.Report_Number),axis=1)\n",
    "    \n",
    "    # Drop duplicates for 'unique_report_id' cases based on length of Result_Text instead of dropping the first observed case\n",
    "    path_df['report_len'] = path_df['Report_Text'].str.len()\n",
    "    \n",
    "    path_df = (path_df\n",
    "      .sort_values(['unique_report_id', 'report_len'])\n",
    "      .drop_duplicates(subset=['unique_report_id'], keep='last', inplace=False, ignore_index=False)\n",
    "      .drop(columns=['report_len'])\n",
    "      .sort_index()\n",
    "     )\n",
    "    \n",
    "    # now set index to unique_report_id\n",
    "    path_df.set_index(keys='unique_report_id', inplace=True, verify_integrity=True)\n",
    "    \n",
    "    # Convert datetime column to pandas date time format\n",
    "    path_df['datetime'] = pd.to_datetime(path_df.loc[:,datetime_col])\n",
    "    \n",
    "    return path_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def truncate_dx_start(pathdf, update=True):\n",
    "    ''' truncate_finaldx(pathdf, update=True)\n",
    "    DESC: For MGH, BWH path reports, find the 'final diagnosis' line of the path report, remove everything preceding. Parse \n",
    "     to extract whether or not there is a final diagnosis line, what that line is, and the full report text (following this line)\n",
    "    \n",
    "    PARAMETERS:\n",
    "    pathdf: pathology dataframe from load_RPDR_path\n",
    "    update: return only MGH, BWH path as a new df or update pathdf with MGH, BWH results\n",
    "    \n",
    "    RETURNS: pathdf or new path dataframe with only MGH, BWH path reports (depending on update bool) with three new columns:\n",
    "    ['has_final_diagnosis'] = did the function find a line of text that it thinks contains final diagnosis line?\n",
    "    ['final_diagnosis_line'] = if has_final_diagnosis == True, then what is the final diagnosis line?\n",
    "    ['Report_Text'] = report text after removing everything above final diagnosis\n",
    "    '''\n",
    "    import re\n",
    "    \n",
    "    # truncate to only final diagnosis (for MGH, BWH reports only)\n",
    "    #print('Filtering only MGH, BWH path reports...')\n",
    "    \n",
    "    # first get only MGH values\n",
    "    #fil_mgh = pathdf.MRN_Type == 'MGH'\n",
    "    df_path = pathdf.copy()\n",
    "    \n",
    "    \n",
    "    # FINAL DIAGNOSIS LINE FINDER\n",
    "    num_reports = df_path.shape[0] # num rows of df_path\n",
    "    has_final_diagnosis_col = []\n",
    "    final_diagnosis_line_col = []\n",
    "    trunc_path_col = []\n",
    "    print('Truncating to only final diagnosis...')\n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = df_path.iloc[i,:].Report_Text\n",
    "        site = df_path.iloc[i,:].MRN_Type\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "\n",
    "        has_final_diagnosis = False\n",
    "        final_diagnosis_line = ''\n",
    "        trunc_path_text = report_text\n",
    "\n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        \n",
    "        if site in ['MGH','BWH','NWH','FH','NSM']:\n",
    "            for line in text_by_line:\n",
    "                lower_line = line.lower().strip()\n",
    "                # capture situation where a line contains liver, biopsy; note will only grab first instance then short circuit\n",
    "                \n",
    "                if has_final_diagnosis==False and ('findings:' in lower_line or\n",
    "                                                   'impression:' in lower_line):\n",
    "                    has_final_diagnosis = True\n",
    "                    final_diagnosis_line = line\n",
    "                    trunc_path_text = '\\n'.join(text_by_line[j:]) # should be a list of this line and all subsequent lines\n",
    "\n",
    "                j=j+1\n",
    "                \n",
    "        has_final_diagnosis_col.append(has_final_diagnosis)\n",
    "        final_diagnosis_line_col.append(final_diagnosis_line)\n",
    "        # either returns the original report or the truncated form if it has a final diagnosis to truncate at\n",
    "        trunc_path_col.append(trunc_path_text)\n",
    "\n",
    "    df_path['has_dx_start'] = has_final_diagnosis_col\n",
    "    df_path['dx_start_line'] = final_diagnosis_line_col\n",
    "    df_path['Report_Text'] = trunc_path_col\n",
    "\n",
    "\n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        #print('Updating input path dataframe with truncated MGH, BWH path reports')\n",
    "        pathdf['has_dx_start'] = False\n",
    "        pathdf['dx_start_line'] = ''\n",
    "        pathdf.update(df_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh, bwh path only file\n",
    "        #print('Returning only MGH, BWH entries with truncated path reports')\n",
    "        return_df = df_path\n",
    "        \n",
    "        print('Done. | Status: ' + str(df_path[df_path.has_dx_start==True].shape[0]) + ' reports with a diagnosis beginning line, ' \n",
    "              + str(df_path[df_path.has_dx_start==False].shape[0]) + ' reports with no diagnosis beginning line')\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def truncate_dx_end(pathdf, update=True, only_dx_start=True):\n",
    "    \n",
    "    #print('Filtering only MGH, BWH path reports...')\n",
    "    fil_subset = pathdf.MRN_Type.isin(['MGH', 'BWH','NWH','FH','NSM'])\n",
    "    df_path = pathdf[fil_subset].copy()\n",
    "    \n",
    "    if only_dx_start:\n",
    "        # check the column exists first:\n",
    "        if 'has_dx_start' in df_path.columns.tolist():\n",
    "            fil_finaldx_trunc = df_path.has_dx_start == True\n",
    "            df_path = df_path[fil_finaldx_trunc]\n",
    "        else:\n",
    "            print('The flag *only_dx_start=True* was passed, however truncate_finaldx() has not been called. Aborting...')\n",
    "            return None\n",
    "\n",
    "    num_reports = df_path.shape[0]\n",
    "    has_lowersec_col = []\n",
    "    lowersec_line_col = []\n",
    "    lowersec_start_LAFD_col = []\n",
    "    trunc_path_col = []\n",
    "    \n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = df_path.iloc[i,:].Report_Text\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "        \n",
    "        has_lowersec = False\n",
    "        lowersec_line = ''\n",
    "        lowersec_start_LAFD = -1\n",
    "        trunc_path_text = report_text\n",
    "        \n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        for line in text_by_line:\n",
    "            lower_line = line.lower()\n",
    "            \n",
    "            if has_lowersec==False and ('recommendation:' in lower_line or\n",
    "                                        'recommend:' in lower_line or\n",
    "                                        'recommendations:' in lower_line or\n",
    "                                        'procedure codes:' in lower_line or\n",
    "                                        'procedure code(s):' in lower_line):\n",
    "                \n",
    "                has_lowersec = True\n",
    "                lowersec_line = line\n",
    "                lowersec_start_LAFD = j\n",
    "                trunc_path_text = '\\n'.join(text_by_line[:j])\n",
    "            j=j+1\n",
    "\n",
    "        has_lowersec_col.append(has_lowersec)\n",
    "        lowersec_line_col.append(lowersec_line)\n",
    "        lowersec_start_LAFD_col.append(lowersec_start_LAFD)\n",
    "        trunc_path_col.append(trunc_path_text)\n",
    "        \n",
    "    df_path['has_dx_end'] = has_lowersec_col\n",
    "    df_path['dx_end_line'] = lowersec_line_col\n",
    "    df_path['dx_end_line_LAFD'] = lowersec_start_LAFD_col\n",
    "    df_path['Report_Text'] = trunc_path_col\n",
    "    \n",
    "    \n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe with truncated MGH, BWH path reports')\n",
    "        pathdf['has_dx_end'] = False\n",
    "        pathdf['dx_end_line'] = ''\n",
    "        pathdf['dx_end_line_LAFD'] = -1\n",
    "        pathdf.update(df_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh path only file\n",
    "        print('Returning MGH, BWH only entries with truncated path reports')\n",
    "        return_df = df_path\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
