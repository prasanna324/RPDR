{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting labs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile labs.py\n",
    "\n",
    "def load_RPDR_labs_multiple(dir_data, path_labs, path_synonyms, datetime_col='Seq_Date_Time', result_col='Result', test_col='Group_Id', delim='|', clean_columns=True, return_discarded=False):\n",
    "    ''' load_labs_multiple(dir_data, path_labs, path_synonyms, datetime_col='Seq_Date_Time', result_col='Result', test_col='Group_Id', delim='|', clean_columns=True):\n",
    "        Sequentially loads all files from RPDR data dump when multiple files have the same name. \n",
    "        \n",
    "        1. Starts in dir_data (should have trailing slash), grabs all sub-folders' names automatically, then sequentially loads: dir_data/[sub-folders]/path_labs (where path_labs is the name of the file)\n",
    "        * Note for whatever reason, on a multiple-split file dump from RPDR the labs, demographics, etc files are all named the exact same, just in different zips\n",
    "        2. Calls the traditional load LFTs function on each file\n",
    "        3. Concatenates all results and returns 1 DF (may be VERY large. ~3-4 gb / 80,000 patients)\n",
    "        \n",
    "        See load_native_data for remainder of parameters which are passed to that function\n",
    "        \n",
    "        '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    # get list of subdirectories\n",
    "    subdirectories = [x[0] for x in os.walk(dir_data)][1:]\n",
    "    \n",
    "    first=True\n",
    "    # for each subdir, use the traditional load function to load data and concat\n",
    "    for subdir in subdirectories:\n",
    "        path_to_labs=subdir+'/'+path_labs\n",
    "        lfts, discarded = load_RPDR_labs(path=path_to_labs,\n",
    "                                           path_synonyms=path_synonyms,\n",
    "                                           datetime_col=datetime_col,\n",
    "                                           result_col=result_col,\n",
    "                                           test_col=test_col, \n",
    "                                           delim=delim,\n",
    "                                           clean_columns=clean_columns)\n",
    "        \n",
    "        if first==True:\n",
    "            concat_pd = lfts\n",
    "            if return_discarded:\n",
    "                concat_discard = discarded\n",
    "            first=False\n",
    "        else:\n",
    "            concat_pd=pd.concat([concat_pd, lfts],ignore_index=True)\n",
    "            if return_discarded:\n",
    "                concat_discard=pd.concat([concat_discard, discarded],ignore_index=True)\n",
    "    \n",
    "    return concat_pd, \n",
    "\n",
    "def load_RPDR_labs(path,path_synonyms,datetime_col='Seq_Date_Time', result_col='Result', test_col='Group_Id', delim='|', clean_columns=True):\n",
    "    '''load_RPDR_labs(path,path_synonyms,datetime_col='Seq_Date_Time', result_col='Result', test_col='Group_Id', delim='|', clean_columns=True):\n",
    "    \n",
    "    DESC: This is the main labs loading function, for loading labs data from an RPDR data pull, and processing lab results. \n",
    "     Does MANY THINGS. \n",
    "     1. Homogenizes column names:\n",
    "         rename result_col to 'result' if not already named result\n",
    "         rename datetime_col to 'datetime' if not already named so; convert this to pd.DateTime format\n",
    "         rename test_col to 'test_desc'\n",
    "    path: path to labs file (in .csv or other text delimited file)\n",
    "    path_synonyms: path to synonyms file (.csv). structure of synonyms file: first row is what you want to call each lab \n",
    "     defined in the test_col column; remainder of rows identify the exact text of labs that should be considered equivalent. \n",
    "     All of these will be homogenized to the row 1 name\n",
    "    datetime_col: name of column with date/time of lab test\n",
    "    result_col: name of column that contains the result of the lab test\n",
    "    test_col: name of the column that contains the name of the lab test (this is what synonyms acts upon)\n",
    "    delim: delimiter of the labs file (the file pointed to by path)\n",
    "    clean_columns: bool. If true, removes all columns except those named the following:\n",
    "     [['EMPI', 'test_desc', 'datetime', 'result_orig', 'result', 'MRN_Type', 'MRN', 'Test_Description', 'Result_Text', 'above_below_assay_limit']]\n",
    "    \n",
    "    RETURNS: lfts, discarded_rows\n",
    "     lfts is the labs as panda database (should really be named labs, but initially developed for only liver function tests (LFTs))\n",
    "     discarded_rows is a second pandas database containing anything removed by the processing\n",
    "     \n",
    "    Note: input result column will be returned as 'result_orig' and the processed result column will be returned as 'result'\n",
    "    '''\n",
    "    # read data\n",
    "    # \n",
    "    # WARNINGS:\n",
    "    # - default behavior is to remove < and >; could add a new column to mark these events if pertinent later\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    # read the data\n",
    "    print('Loading data from ' + path)\n",
    "    lfts = pd.read_csv(path,delimiter=delim, error_bad_lines=False)\n",
    "    \n",
    "#     if result_col != 'result':\n",
    "#         lfts['result'] = lfts.loc[:,result_col]\n",
    "#     else:\n",
    "#         # result col is already named result. rename it\n",
    "#         lfts['result_orig'] = lfts['result']\n",
    "\n",
    "    ## Mod 1 ##\n",
    "    if result_col in lfts.columns:\n",
    "        lfts.rename(columns={result_col: 'result_orig'}, inplace=True)\n",
    "        lfts['result'] = lfts.loc[:,'result_orig']\n",
    "    else:\n",
    "        raise ValueError('Incorrect name specified for result column')\n",
    "    ## Mod 1 ##\n",
    "    \n",
    "    # convert datetime column to datetime format\n",
    "    if datetime_col != 'datetime':\n",
    "        lfts['datetime'] = pd.to_datetime(lfts.loc[:,datetime_col])\n",
    "        lfts.drop(labels=datetime_col, axis=1, inplace=True)\n",
    "    else:\n",
    "        lfts['datetime'] = pd.to_datetime(lfts['datetime'])\n",
    "    \n",
    "    if test_col != 'test_desc':\n",
    "        lfts['test_desc'] = lfts.loc[:,test_col]\n",
    "    else:\n",
    "        # test_desc col is already named test_desc. rename it\n",
    "        lfts['test_desc_orig'] = lfts['test_desc']\n",
    "    \n",
    "    ######################\n",
    "    # Identify synonyms of labs and homogenize based on a file called lab_synonyms.csv\n",
    "    # structure: first row is what you want to call each lab; below the col are all the synonyms to change to the header name\n",
    "    syn=pd.read_csv(path_synonyms)\n",
    "    correct_lab_names=syn.columns.tolist()\n",
    "    for correct_lab in correct_lab_names:\n",
    "        alternate_names_to_replace=syn[correct_lab].tolist()\n",
    "        for alt in alternate_names_to_replace:\n",
    "            # irregular length columns, if this column has nan's at the end, don't cycle through them\n",
    "            if isinstance(alt,str):\n",
    "                lfts.test_desc.replace(alt,correct_lab,regex=False, inplace=True)\n",
    "            \n",
    "    # error checking\n",
    "    if set(correct_lab_names) == set(lfts.test_desc.unique().tolist()):\n",
    "        print('Successful homogenization of lab names')\n",
    "        print(correct_lab_names)\n",
    "    else:\n",
    "        got_list=set(lfts.test_desc.unique().tolist())\n",
    "        expected_list=set(correct_lab_names)\n",
    "        print('FAILED TO HOMOGENIZE NAMES')\n",
    "        print('Expected : ')\n",
    "        print(expected_list)\n",
    "        print('Of these, got only : ')\n",
    "        print(got_list & expected_list)\n",
    "        print('Got additionally : ')\n",
    "        print(got_list-expected_list)\n",
    "        print('...and we are missing : ')\n",
    "        print(expected_list-got_list)\n",
    "    \n",
    "    ######################\n",
    "    # CERTIFY INDIVIDUAL RESULTS THAT REQUIRE SPECIAL HANDLING\n",
    "    # NUMERICS\n",
    "    list_numeric_labs = ['ALT','AST','AKP','DBILI','TBILI', 'CR','INR','IGG']\n",
    "\n",
    "    lfts['above_below_assay_limit'] = 0\n",
    "\n",
    "    fil = lfts.test_desc.isin(list_numeric_labs)\n",
    "\n",
    "    # def upper and lower bound finder\n",
    "    def upper_lower_bound_finder(row):\n",
    "        if not isinstance(row.result, float):\n",
    "            if '<' in row.result:\n",
    "                return -1\n",
    "            elif '>' in row.result:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    # def upper and lower bound finder\n",
    "    def remove_gg_ll_signs(row):\n",
    "        if isinstance(row, str):\n",
    "            if '<' in row:\n",
    "                return row.replace('<','')\n",
    "            elif '>' in row:\n",
    "                return row.replace('>','')\n",
    "            else:\n",
    "                return row\n",
    "\n",
    "    # first mark whether a result is at the upper or lower limit (otherwise NaN)\n",
    "    lfts.loc[fil, 'above_below_assay_limit'] = lfts.loc[fil, ['result', 'above_below_assay_limit']].apply(upper_lower_bound_finder, axis=1)\n",
    "\n",
    "    # remove greater than and less than signs\n",
    "    lfts.loc[fil, 'result'] = lfts.loc[fil, 'result'].apply(remove_gg_ll_signs)\n",
    "    \n",
    "    # now that we've removed greater than and less than signs, data should be numeric. Anything non-numeric (in this category) is crap, \n",
    "    # e.g., \"REFUSED\", \"HEMOLYZED\" etc\n",
    "    \n",
    "    # filter for coercing data to numeric, catching NaNs (text)\n",
    "    print('Removing non-numeric result values...')\n",
    "    lfts.loc[fil, 'result'] = pd.to_numeric(lfts.loc[fil, 'result'], errors='coerce')\n",
    "    # hold on to removed rows -- error checking\n",
    "    removed_rows=lfts[(fil) & lfts.result.isnull()].copy()\n",
    "    # remove these rows\n",
    "    lfts.drop(lfts[(fil) & lfts.result.isnull()].index, inplace=True)\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    # CERTIFY INDIVIDUAL RESULTS THAT REQUIRE SPECIAL HANDLING\n",
    "    # ANTIBODY TITERS\n",
    "    \n",
    "    list_titer_labs = ['LKM','ASMA', 'ANA', 'AMA', 'SLA']\n",
    "\n",
    "    fil_ab = lfts.test_desc.isin(list_titer_labs)\n",
    "    \n",
    "    if not lfts[fil_ab].empty:\n",
    "\n",
    "        def titer_interp(row):\n",
    "            import math\n",
    "            import re\n",
    "\n",
    "            bool_switched_result_resultext=False\n",
    "\n",
    "            if isinstance(row.result, float):\n",
    "                if row.result < 20: # antibody titer cutoff for LKM and works for ANA, ASMA\n",
    "                    return 0\n",
    "                elif math.isnan(row.result):\n",
    "                    if isinstance(row.Result_Text,str):\n",
    "                        this_string=row.Result_Text\n",
    "                        bool_switched_result_resultext=True\n",
    "                    else:\n",
    "                        return row.result\n",
    "                else:\n",
    "                    return row.result\n",
    "\n",
    "            # function I'm going to use a bunch of times:\n",
    "            def all_numbers_within_n_chars_of_word(text, word, n):\n",
    "                idx_zero_pos_of_word=text.lower().find(word)\n",
    "                if len(text[idx_zero_pos_of_word:]) < n:\n",
    "                    sub_string_to_return=text[idx_zero_pos_of_word:]\n",
    "                else:\n",
    "                    sub_string_to_return=text[idx_zero_pos_of_word:idx_zero_pos_of_word+n]\n",
    "\n",
    "                return find_all_num_in_string(sub_string_to_return)\n",
    "\n",
    "            # CASES AT THIS POINT. Either this_string holds a swapped text or doesn't. Any string in result hasn't been accounted for yet\n",
    "            # most of the logic will be shared, nevertheless keep them separate because, e.g., a single number in result is usually the value we want\n",
    "            #  while a single number in result text might not be\n",
    "\n",
    "            if isinstance(row.result, str):\n",
    "                numbers = find_all_num_in_string(row.result)\n",
    "\n",
    "                if '<' in row.result:\n",
    "                    return 0\n",
    "                elif 'ANA SCREEN POSITIVE, TITRE PERFORMED' in row.result or 'POSITIVE - SEE TITER' in row.result:\n",
    "                    # this category will get removed; there's always a titer separately reported at same time point\n",
    "                    return 'see titer'\n",
    "                \n",
    "                    \n",
    "                ## FIRST IDENTIFY POSITIVELY OR NEGATIVELY IDENTIFIED EXAMPLES\n",
    "                elif 'negative' in row.result.lower() and not 'positive' in row.result.lower():\n",
    "                    return 0\n",
    "                elif 'positive' in row.result.lower() and not 'negative' in row.result.lower():\n",
    "                    \n",
    "                    if len(numbers) == 1:\n",
    "                        return numbers[0]\n",
    "                    elif len(numbers) == 2 and numbers[0]==1:\n",
    "                        return numbers[1]\n",
    "                    \n",
    "                    elif len(numbers) == 4 and numbers[2]==1:\n",
    "                        return numbers[3]\n",
    "                    \n",
    "                    else: \n",
    "                        result_text=row.Result_Text\n",
    "                        if isinstance(result_text,str):\n",
    "                            \n",
    "                            ## Some cases doenst contain the word 'positive' in Result_text which is generating a random incorrect result\n",
    "                            if 'positive' in result_text.lower():\n",
    "                                numbers=all_numbers_within_n_chars_of_word(result_text, 'positive', n=26)\n",
    "                                if len(numbers) == 1:\n",
    "                                    return numbers[0]\n",
    "                                elif len(numbers) == 2 and numbers[0]==1:\n",
    "                                    return numbers[1]\n",
    "                                elif len(numbers) > 2:\n",
    "                                    this_string=row.Result_Text.lower()\n",
    "                                    if isinstance(this_string,str):\n",
    "                                        idx_titer=this_string.find('titer')\n",
    "                                        if len(row.Result_Text[idx_titer:]) <= 17:\n",
    "                                            search_text=row.Result_Text[idx_titer:]\n",
    "                                        else:\n",
    "                                            search_text=row.Result_Text[idx_titer:idx_titer+17]\n",
    "                                        numbers=find_all_num_in_string(search_text)\n",
    "                                        if len(numbers) == 1:\n",
    "                                            return numbers[0]\n",
    "                                        elif len(numbers) == 2 and numbers[0]==1:\n",
    "                                            return numbers[1]\n",
    "                            else:\n",
    "                                return 20\n",
    "\n",
    "                elif 'positive' in row.result.lower() and 'negative' in row.result.lower():\n",
    "                    # both pos and neg present; find the text following the 'positive' word (26 chars)\n",
    "                    numbers=all_numbers_within_n_chars_of_word(row.result, 'positive', n=26)\n",
    "                    if len(numbers) == 1:\n",
    "                        return numbers[0]\n",
    "                    elif len(numbers) == 2 and numbers[0]==1:\n",
    "                        return numbers[1]\n",
    "                    else:\n",
    "                        # possible it's farther out?\n",
    "                        text=row.result[index_positive:]\n",
    "                        numbers=find_all_num_in_string(text)\n",
    "                        print('pos & neg text present but no value within 26 chars; went out on a limb and returning : ' + str(numbers[1]))\n",
    "                        return numbers[1]\n",
    "\n",
    "                # okay, so the words 'positive' and 'negative' aren't present\n",
    "                elif len(numbers) == 1:\n",
    "                    return numbers[0]\n",
    "                elif len(numbers) == 2 and numbers[0]==1:\n",
    "                    # pair of numbers returned; make sure the first value is 1\n",
    "                    return numbers[1]\n",
    "\n",
    "            # CASES AT THIS POINT. Either this_string holds a swapped text or doesn't. Any interpretable string has been returned\n",
    "\n",
    "            if bool_switched_result_resultext:\n",
    "                numbers = find_all_num_in_string(this_string)\n",
    "\n",
    "                ## FIRST IDENTIFY POSITIVELY OR NEGATIVELY IDENTIFIED EXAMPLES\n",
    "                if 'negative' in this_string.lower() and not 'positive' in this_string.lower():\n",
    "                    return 0\n",
    "                elif 'positive' in this_string.lower() and not 'negative' in this_string.lower():\n",
    "                    ## Positive at logic is not working when there are 4 numbers. Removed the if statement\n",
    "                    ## Example: Positive at 1:40 and 1:160 (endpoint)\n",
    "                    ## Finding all numbers within a close proximity of 'positive' seems to be working for all cases\n",
    "                    numbers=all_numbers_within_n_chars_of_word(this_string, 'positive', n=26)\n",
    "                    if len(numbers) == 1:\n",
    "                        return numbers[0]\n",
    "                    elif len(numbers) == 2 and numbers[0]==1:\n",
    "                        return numbers[1]\n",
    "                    elif len(numbers) == 4 and numbers[2]==1:\n",
    "                        return numbers[3]\n",
    "                    elif len(numbers)>0:\n",
    "                        # first try to match the expression 'positive at 1:x'\n",
    "                        m = re.search('positive at 1:(\\d+)', this_string.lower())\n",
    "                        if m:\n",
    "                            return m.group(1)\n",
    "                        else:\n",
    "                            # no 'positive at' expressions.. get all the numbers and return the largest one, and print\n",
    "                            #  result text because this is a weird case..\n",
    "                            max_num = max(numbers)\n",
    "                            print('positive only in result text but neither 1 nor 2 numbers, going on limb and taking : ' + str(max_num))\n",
    "                            print(this_string)\n",
    "                            return max_num\n",
    "                    \n",
    "                elif 'positive' in this_string.lower() and 'negative' in this_string.lower():\n",
    "                    # both pos and neg present; find the text following the 'positive' word (15 chars)\n",
    "                    index_positive=this_string.lower().find('positive')\n",
    "                    if len(this_string[index_positive:]) <= 26:\n",
    "                        text=this_string[index_positive:]\n",
    "                    else:\n",
    "                        text=this_string[index_positive:index_positive+26]\n",
    "                    numbers=find_all_num_in_string(text)\n",
    "        #             print(text)\n",
    "        #             print(numbers)\n",
    "                    if len(numbers) == 1:\n",
    "                        return numbers[0]\n",
    "                    elif len(numbers) == 2 and numbers[0]==1:\n",
    "                        return numbers[1]\n",
    "                    elif len(numbers) == 4:\n",
    "                        return max(numbers)\n",
    "                    elif 'negative at' in this_string.lower():\n",
    "                        return 0\n",
    "                # okay, so the words 'positive' and 'negative' aren't present\n",
    "                elif len(numbers) == 1:\n",
    "                    return numbers[0]\n",
    "                elif len(numbers) == 2 and numbers[0]==1:\n",
    "                    return numbers[1]\n",
    "\n",
    "\n",
    "            return row.result\n",
    "\n",
    "        # first mark whether a result is at the upper or lower limit (otherwise NaN)\n",
    "        lfts.loc[fil_ab, 'result'] = lfts.loc[fil_ab, ['result', 'Result_Text']].apply(titer_interp, axis=1)\n",
    "\n",
    "        print('Cleaning up antibody titer results...')\n",
    "        lfts.loc[fil_ab, 'result'] = pd.to_numeric(lfts.loc[fil_ab, 'result'], errors='coerce')\n",
    "        # hold on to removed rows -- error checking\n",
    "        removed_rows_ab=lfts[(fil_ab) & lfts.result.isnull()].copy()\n",
    "        # remove these reows\n",
    "        lfts.drop(lfts[(fil_ab) & lfts.result.isnull()].index, inplace=True)\n",
    "    \n",
    "        ######################\n",
    "        # COMBINE DISCARDED DATA\n",
    "        removed_rows = pd.concat([removed_rows,removed_rows_ab],axis=0)\n",
    "    \n",
    "    ######################\n",
    "    # REMOVE UNUSED/DISTRACTING/PRECURSOR COLUMNS\n",
    "    if clean_columns:\n",
    "        # easier to define as what we want to keep\n",
    "        lfts = lfts[['EMPI', 'test_desc', 'datetime', 'result_orig', 'result', 'MRN_Type', 'MRN', 'Test_Description', 'Result_Text', 'above_below_assay_limit']].copy()\n",
    "        \n",
    "#     from IPython import embed; embed()\n",
    "        \n",
    "    # enforce the EMPI column is strings for later\n",
    "    lfts['EMPI'] = lfts.EMPI.astype(str)\n",
    "        \n",
    "    print('...Done')\n",
    "    \n",
    "    return lfts, removed_rows\n",
    "\n",
    "def find_all_num_in_string(sentence):\n",
    "    # accepts a sentence; returns an array of all numbers in the sentence\n",
    "    import re\n",
    "    \n",
    "    s = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', sentence)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
