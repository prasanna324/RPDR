{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting procedure.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile procedure.py\n",
    "\n",
    "def load_RPDR_prc_multiple(dir_data, fname, delimiter='|', datetime_col='Date'):\n",
    "    ''' load_RPDR_prc_multiple(dir_data, fname, delimiter='|', datetime_col='Date'):\n",
    "        Sequentially loads all files from RPDR data dump when output is split. \n",
    "        \n",
    "        1. Starts in dir_data (should have trailing slash), grabs all sub-folders' names automatically, then sequentially loads: dir_data/[sub-folders]/fname (where fname is the name of the file)\n",
    "        * Note for whatever reason, on a multiple-split file dump from RPDR the labs, demographics, etc files are all named the exact same, just in different zips\n",
    "        2. Calls the traditional load path function on each file\n",
    "        3. Concatenates all results and returns 1 DF\n",
    "        \n",
    "        See load_native_data for remainder of parameters which are passed to that function\n",
    "        \n",
    "        '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    # get list of subdirectories\n",
    "    subdirectories = [x[0] for x in os.walk(dir_data)][1:]\n",
    "    \n",
    "    first=True\n",
    "    # for each subdir, use the traditional load function to load data and concat\n",
    "    for subdir in subdirectories:\n",
    "        path_to_path=subdir+'/'+fname\n",
    "        path = load_RPDR_prc(path=path_to_path,\n",
    "                              delimiter=delimiter,\n",
    "                              datetime_col=datetime_col)\n",
    "        \n",
    "        if first==True:\n",
    "            concat_pd = path\n",
    "            first=False\n",
    "        else:\n",
    "            concat_pd=pd.concat([concat_pd, path],ignore_index=True)\n",
    "    \n",
    "    return concat_pd\n",
    "\n",
    "\n",
    "def load_RPDR_prc(path,delimiter='|', datetime_col='Date'):\n",
    "    ''' load_RPDR_prc(path, delimiter='|', datetime_col='Date'):\n",
    "        Loads RPDR procedures file as pandas dataframe\n",
    "        \n",
    "        PARAMETERS:\n",
    "        path: path to csv file or other text delimited file\n",
    "        delimiter: delimiter for path file\n",
    "        datetime_col: column name containing date/time information for each path report\n",
    "\n",
    "        returns: pandas dataframe containing path information\n",
    "        \n",
    "        WARNINGS:\n",
    "        1. Current function automatically searches for path + 'multiline_corrected', *if present* it assumes that is the correct \n",
    "            file. E.g., path='/data/path.txt', it searches for '/data/path_multiline_corrected.txt'.\n",
    "        2. It will not overwrite this file if present\n",
    "    \n",
    "        '''\n",
    "    import pandas as pd\n",
    "    import os.path\n",
    "    from os import path as os_path\n",
    "    \n",
    "    write_path = path.replace('.','_multiline_corrected.')\n",
    "    if os_path.exists(write_path)==False:\n",
    "        print('Reformatting path file to allow multi-line report text to be readable, saving as : {}'.format(write_path))\n",
    "        \n",
    "        with open(write_path,'w') as file_w:\n",
    "            with open(path) as file_r:\n",
    "                for i in range(1):\n",
    "                    first_line = next(file_r)\n",
    "                    file_w.write(first_line)\n",
    "                for i,line in enumerate(file_r):\n",
    "                    # Replace single quote with double quotes in all the lines\n",
    "                    line = line.replace('\"', '\"\"')\n",
    "            \n",
    "                    # Number of times \"|\" is present in a line\n",
    "                    count = line.count(\"|\")\n",
    "                    \n",
    "                    if count not in [9,14]:\n",
    "                        # Replace the last occurence of '|' with '|\"'\n",
    "                        line = line.replace('\\n', '')\n",
    "                    file_w.write(line)\n",
    "        file_r.close()\n",
    "        file_w.close()\n",
    "        \n",
    "    path = write_path\n",
    "    \n",
    "    # Read the processed .csv file from path location\n",
    "    print('Reading from : ' + path)\n",
    "    path_df = pd.read_csv(path, sep=delimiter, dtype=str)\n",
    "    \n",
    "    # Convert datetime column to pandas date time format\n",
    "    path_df['datetime'] = pd.to_datetime(path_df.loc[:,datetime_col])\n",
    "    \n",
    "    return path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
