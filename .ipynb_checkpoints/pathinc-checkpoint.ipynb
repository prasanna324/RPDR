{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pathinc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pathinc.py\n",
    "\n",
    "def load_RPDR_path_multiple(dir_data, fname, delimiter='|', datetime_col='Report_Date_Time'):\n",
    "    ''' load_RPDR_path_multiple(dir_data, fname, delimiter='\\t', datetime_col='Report_Date_Time'):\n",
    "        Sequentially loads all files from RPDR data dump when output is split. \n",
    "        \n",
    "        1. Starts in dir_data (should have trailing slash), grabs all sub-folders' names automatically, then sequentially loads: dir_data/[sub-folders]/fname (where fname is the name of the file)\n",
    "        * Note for whatever reason, on a multiple-split file dump from RPDR the labs, demographics, etc files are all named the exact same, just in different zips\n",
    "        2. Calls the traditional load path function on each file\n",
    "        3. Concatenates all results and returns 1 DF\n",
    "        \n",
    "        See load_native_data for remainder of parameters which are passed to that function\n",
    "        \n",
    "        '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    d\n",
    "    # get list of subdirectories\n",
    "    subdirectories = [x[0] for x in os.walk(dir_data)][1:]\n",
    "    \n",
    "    first=True\n",
    "    # for each subdir, use the traditional load function to load data and concat\n",
    "    for subdir in subdirectories:\n",
    "        path_to_path=subdir+'/'+fname\n",
    "        path = load_RPDR_path(path=path_to_path,\n",
    "                              delimiter=delimiter,\n",
    "                              datetime_col=datetime_col)\n",
    "        \n",
    "        if first==True:\n",
    "            concat_pd = path\n",
    "            first=False\n",
    "        else:\n",
    "            concat_pd=pd.concat([concat_pd, path],ignore_index=True)\n",
    "    \n",
    "    return concat_pd\n",
    "\n",
    "def load_RPDR_path(path,delimiter='|', datetime_col='Report_Date_Time'):\n",
    "    ''' load_RPDR_path(path,string_format=False,delimiter='|', datetime_col='Report_Date_Time')\n",
    "    DESC: loads an RPDR pathology file to pandas \n",
    "    1. removes deleted, canceled and in process path reports\n",
    "    2. removes duplicate path reports, keeping the first entry\n",
    "    3. resets index to 'Report_Number' column\n",
    "    4. converts datetime_col to pd.DateTime format\n",
    "    \n",
    "    PARAMETERS:\n",
    "    path: path to csv file or other text delimited file\n",
    "    delimiter: delimiter for path file\n",
    "    datetime_col: column name containing date/time information for each path report\n",
    "    \n",
    "    returns: pandas dataframe containing path information\n",
    "    \n",
    "    WARNINGS:\n",
    "    1. Current function automatically searches for path + 'multiline_corrected', *if present* it assumes that is the correct \n",
    "        file. E.g., path='/data/path.txt', it searches for '/data/path_multiline_corrected.txt'.\n",
    "    2. It will not overwrite this file if present\n",
    "    \n",
    "    TO-DO:\n",
    "    1. Update path report selection when there are near-duplicates. These are almost always of the form 'Final' and 'Updated', \n",
    "        of which, when duplicated, we should take the 'Updated' report. I have looked at about 10 examples so far (Marc)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import os.path\n",
    "    from os import path as os_path\n",
    "    \n",
    "    ## default Report_Text format is multi-line. If string_format==True, convert multi-line text by double-quoting all quotes\n",
    "    ##  (which allows read_csv to read through by default), and enclosing full report in single-quotes\n",
    "    write_path = path.replace('.txt','_multiline_corrected.txt')\n",
    "    if os_path.exists(write_path)==False:\n",
    "        print('Reformatting path file to allow multi-line report text to be readable, saving as : {}'.format(write_path))\n",
    "        f = open(path,'r')\n",
    "        filedata = f.read()\n",
    "        f.close()\n",
    "        newdata = filedata.replace('\"', '\"\"')\n",
    "        ## Mod 1 ##\n",
    "        # Replacing Accession number with PAT to deal with Report_Text's that doesn't contain the word \"Accession number\"\n",
    "        newdata = newdata.replace('|PAT|', '|PAT|\"')\n",
    "        ## Mod 1 ##\n",
    "        newdata = newdata.replace('[report_end]', '[report_end]\"')\n",
    "        f2 = open(write_path,'w')\n",
    "        f2.write(newdata)\n",
    "        f2.close()\n",
    "        \n",
    "    path = write_path\n",
    "    \n",
    "    print('Reading from : ' + path)\n",
    "    path_df = pd.read_csv(path, sep=delimiter, dtype=str)\n",
    "    \n",
    "    # unique_identifier. Requires some explanation.. report_number SHOULD be unique (it is literally the accession\n",
    "    #  number for finding a block of tissue), however it is NOT in some specific examples of NSMC and MGH. E.g., \n",
    "    #  in all_RPDR_path, report numbers  : \n",
    "    # 'S11-5510', 'S14-3070', 'S17-25856', 'S13-2400', 'S14-9841', 'S13-3071',\n",
    "    #    'S12-6506', 'S14-218', 'S12-3414', 'S13-32', 'S13-6114', 'S12-2481',\n",
    "    #    'S13-1077', 'S14-41', 'S13-8207', 'S12-10612', 'S12-5964', 'S10-9798',\n",
    "    #    'S09-10295', 'S16-15842', 'S14-8374', 'S12-3350', 'S12-6495', 'S14-785',\n",
    "    #    'S16-183'\n",
    "    #  all give duplicates for NSMC & MGH. And they're *different* patients, totally diff reports\n",
    "    #  solution: append EMPI (unique per patient) to report_number to screen out these cases, operate on this concatenated report id\n",
    "    path_df['unique_report_id'] = path_df.apply(lambda x: str(x.EMPI) + '_' + str(x.Report_Number),axis=1)\n",
    "    \n",
    "    # remove deleted, cancelled, and in-process path reports\n",
    "    # bad_reports = (path_df.Report_Status == 'Deleted') | (path_df.Report_Status == 'Cancelled') | (path_df.Report_Status == 'In Process') | (path_df.Report_Status == 'Preliminary') | (path_df.Report_Status == 'Hold')  | (path_df.Report_Status == 'Pending')\n",
    "    bad_statuses=['Deleted', 'Cancelled', 'In Process', 'Preliminary', 'Hold', 'Pending','Unknown','In Revision', 'Not Verified']\n",
    "    bad_reports = path_df.Report_Status.isin(bad_statuses)\n",
    "    \n",
    "    # drop rows with any of these features\n",
    "    path_df2 = path_df[~bad_reports].copy()\n",
    "    \n",
    "    ## Mod 2 ##\n",
    "    # Drop duplicates for 'unique_report_id' cases based on length of Result_Text instead of dropping the first observed case\n",
    "    path_df2['report_len'] = path_df2['Report_Text'].str.len()\n",
    "    \n",
    "    path_df2 = (path_df2\n",
    "      .sort_values(['unique_report_id', 'report_len'])\n",
    "      .drop_duplicates(subset=['unique_report_id'], keep='last', inplace=False, ignore_index=False)\n",
    "      .drop(columns=['report_len'])\n",
    "      .sort_index()\n",
    "     )\n",
    "    ## Mod 2 ##\n",
    "    \n",
    "    # now set index to unique_report_id\n",
    "    path_df2.set_index(keys='unique_report_id', inplace=True, verify_integrity=True)\n",
    "    \n",
    "    # set date time as datetime\n",
    "    path_df2['datetime'] = pd.to_datetime(path_df2.loc[:,datetime_col])\n",
    "\n",
    "    return path_df2\n",
    "\n",
    "def truncate_finaldx(pathdf, update=True):\n",
    "    ''' truncate_finaldx(pathdf, update=True)\n",
    "    DESC: For path reports, find the 'final diagnosis' line of the path report, remove everything preceding. Parse \n",
    "     to extract whether or not there is a final diagnosis line, what that line is, and the full report text (following this line)\n",
    "    \n",
    "    PARAMETERS:\n",
    "    pathdf: pathology dataframe from load_RPDR_path\n",
    "    update: return preprocessed path as a new df or update pathdf\n",
    "    \n",
    "    RETURNS: pathdf or new path dataframe with only MGH, BWH path reports (depending on update bool) with three new columns:\n",
    "    ['has_final_diagnosis'] = did the function find a line of text that it thinks contains final diagnosis line?\n",
    "    ['final_diagnosis_line'] = if has_final_diagnosis == True, then what is the final diagnosis line?\n",
    "    ['Report_Text'] = report text after removing everything above final diagnosis\n",
    "    '''\n",
    "    import re\n",
    "    \n",
    "    # truncate to only final diagnosis\n",
    "    \n",
    "    # first get only MGH values\n",
    "    #fil_mgh = pathdf.MRN_Type == 'MGH'\n",
    "    df_path = pathdf.copy()\n",
    "    \n",
    "    \n",
    "    # FINAL DIAGNOSIS LINE FINDER\n",
    "    num_reports = df_path.shape[0] # num rows of df_path\n",
    "    has_final_diagnosis_col = []\n",
    "    final_diagnosis_line_col = []\n",
    "    trunc_path_col = []\n",
    "    print('Truncating to only final diagnosis...')\n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = df_path.iloc[i,:].Report_Text\n",
    "        site = df_path.iloc[i,:].MRN_Type\n",
    "        description = df_path.iloc[i,:].Report_Description\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "\n",
    "        has_final_diagnosis = False\n",
    "        final_diagnosis_line = ''\n",
    "        trunc_path_text = report_text\n",
    "        non_excl = not bool(re.search(r'\\bfetus\\b|\\bfetopsy\\b|\\bautopsy\\b', report_text.lower()))\n",
    "\n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        \n",
    "        if site in ['MGH','BWH','NWH','FH','NSM'] and non_excl:\n",
    "            for line in text_by_line:\n",
    "                lower_line = line.lower().strip()\n",
    "                # capture situation where a line contains liver, biopsy; note will only grab first instance then short circuit\n",
    "                \n",
    "                if (has_final_diagnosis==False) and ((\n",
    "                            ('Final' in line or 'Pathologic' in line or\n",
    "                            'FINAL' in line or 'PATHOLOGIC' in line) and 'diagnosis' in lower_line) or\n",
    "                            (lower_line.startswith('diagnosis:')) or\n",
    "                            (line.strip()=='Diagnosis') or\n",
    "                            (line.startswith('SPECIMEN(S):'))) and not (\n",
    "                                            'amend' in lower_line or\n",
    "                                            'final diagnosis by' in lower_line or\n",
    "                                            'clinical data' in lower_line or\n",
    "                                            'cytogenetic' in lower_line or\n",
    "                                            'reason for' in lower_line or\n",
    "                                            'gross description' in lower_line or\n",
    "                                            'original' in lower_line or\n",
    "                                            'epithelial' in lower_line or\n",
    "                                            'unsatisfactory for evaluation' in lower_line or\n",
    "                                            'clinical history' in lower_line):\n",
    "                    has_final_diagnosis = True\n",
    "                    final_diagnosis_line = line\n",
    "                    trunc_path_text = '\\n'.join(text_by_line[j:]) # should be a list of this line and all subsequent lines\n",
    "\n",
    "                j=j+1\n",
    "                \n",
    "        has_final_diagnosis_col.append(has_final_diagnosis)\n",
    "        final_diagnosis_line_col.append(final_diagnosis_line)\n",
    "        # either returns the original report or the truncated form if it has a final diagnosis to truncate at\n",
    "        trunc_path_col.append(trunc_path_text)\n",
    "\n",
    "    df_path['has_final_diagnosis'] = has_final_diagnosis_col\n",
    "    df_path['final_diagnosis_line'] = final_diagnosis_line_col\n",
    "    df_path['Report_Text'] = trunc_path_col\n",
    "\n",
    "\n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe with truncated path reports')\n",
    "        pathdf['has_final_diagnosis'] = False\n",
    "        pathdf['final_diagnosis_line'] = ''\n",
    "        pathdf.update(df_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh, bwh path only file\n",
    "        print('Returning entries with truncated path reports')\n",
    "        return_df = df_path\n",
    "        \n",
    "        print('Done. | Status: ' + str(df_path[df_path.has_final_diagnosis==True].shape[0]) + ' reports with a final diagnosis, ' \n",
    "              + str(df_path[df_path.has_final_diagnosis==False].shape[0]) + ' reports with no final diagnosis')\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def truncate_lower(pathdf, update=True, only_finaldx=True):\n",
    "    \n",
    "    #print('Filtering only MGH, BWH path reports...')\n",
    "    fil_subset = pathdf.MRN_Type.isin(['MGH', 'BWH','NWH','FH','NSM'])\n",
    "    df_path = pathdf[fil_subset].copy()\n",
    "    \n",
    "    if only_finaldx:\n",
    "        # check the column exists first:\n",
    "        if 'has_final_diagnosis' in df_path.columns.tolist():\n",
    "            fil_finaldx_trunc = df_path.has_final_diagnosis == True\n",
    "            df_path = df_path[fil_finaldx_trunc]\n",
    "        else:\n",
    "            print('The flag *only_finaldx=True* was passed, however truncate_finaldx() has not been called. Aborting...')\n",
    "            return None\n",
    "\n",
    "    num_reports = df_path.shape[0]\n",
    "    has_lowersec_col = []\n",
    "    lowersec_line_col = []\n",
    "    lowersec_start_LAFD_col = []\n",
    "    trunc_path_col = []\n",
    "    \n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = df_path.iloc[i,:].Report_Text\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "        \n",
    "        has_lowersec = False\n",
    "        lowersec_line = ''\n",
    "        lowersec_start_LAFD = -1\n",
    "        trunc_path_text = report_text\n",
    "        \n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        for line in text_by_line:\n",
    "            lower_line = line.lower()\n",
    "            \n",
    "            trimmed_line = remove_extra_spaces(line)\n",
    "            timmed_lower_line = remove_extra_spaces(lower_line)\n",
    "            \n",
    "            if has_lowersec==False and ('CLINICAL DATA' in trimmed_line or\n",
    "                                        'by his/her signature below' in timmed_lower_line or\n",
    "                                        'Final Diagnosis by' in trimmed_line or\n",
    "                                        'electronically signed out' in timmed_lower_line or\n",
    "                                        'diagnosis by:' in timmed_lower_line or\n",
    "                                        'gross description:' in timmed_lower_line or\n",
    "                                        'o. r. consultation report:' in timmed_lower_line or\n",
    "                                        'Reports to:' in trimmed_line or\n",
    "                                        'SPECIMEN TYPE:' in trimmed_line or\n",
    "                                        'clinical diagnosis & history' in lower_line or\n",
    "                                        'pathology dept report date/time' in lower_line or\n",
    "                                        'Clinical History:'==line):\n",
    "                \n",
    "                has_lowersec = True\n",
    "                lowersec_line = line\n",
    "                lowersec_start_LAFD = j\n",
    "                trunc_path_text = '\\n'.join(text_by_line[:j])\n",
    "            j=j+1\n",
    "\n",
    "        has_lowersec_col.append(has_lowersec)\n",
    "        lowersec_line_col.append(lowersec_line)\n",
    "        lowersec_start_LAFD_col.append(lowersec_start_LAFD)\n",
    "        trunc_path_col.append(trunc_path_text)\n",
    "        \n",
    "    df_path['has_lowersec'] = has_lowersec_col\n",
    "    df_path['lowersec_line'] = lowersec_line_col\n",
    "    df_path['lowersec_start_LAFD'] = lowersec_start_LAFD_col\n",
    "    df_path['Report_Text'] = trunc_path_col\n",
    "    \n",
    "    \n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe with truncated path reports')\n",
    "        pathdf['has_lowersec'] = False\n",
    "        pathdf['lowersec_line'] = ''\n",
    "        pathdf['lowersec_start_LAFD'] = -1\n",
    "        pathdf.update(df_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh path only file\n",
    "        print('Returning entries with truncated path reports')\n",
    "        return_df = df_path\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def is_liver_biopsy(pathdf, update=True, only_finaldx=True): \n",
    "    ''' is_liver_biopsy(pathdf, update=True, only_finaldx=True)\n",
    "    DESC: For path reports, determine whether this pathology report is from a liver biopsy. \n",
    "    REQUIRES: a column named Report_Text containing the full text of the path report; if only_finaldx is true, must have run\n",
    "     truncate_finaldx() first \n",
    "    \n",
    "    PARAMETERS:\n",
    "    pathdf: pathology dataframe from load_RPDR_path (or subsequent modification)\n",
    "    update: return preprocessed path as a new df or update pathdf results\n",
    "    only_finaldx: bool, if True, only update rows where has_final_diagnosis==True\n",
    "    \n",
    "    RETURNS: pathdf or new path dataframe with preprocessed path reports (depending on update bool) with three new columns:\n",
    "    ['is_liver_biopsy'] = bool, is this a liver biopsy or not?\n",
    "    ['is_liver_biopsy_line'] = text of liver biopsy line if above true\n",
    "    ['liver_biopsy_LAFD'] = LAFD=Lines After Final Diagnosis, ie if final diagnosis line on line 12, and liver biopsy line 16, =16-12\n",
    "     This is to help screen for oddities, as there is a typical, rough number of lines between these entries.\n",
    "    '''    \n",
    "    \n",
    "    import re\n",
    "    \n",
    "    #print('Filtering only MGH, BWH path reports...')\n",
    "    #fil_mgh = pathdf.MRN_Type == 'MGH'\n",
    "    df_path = pathdf.copy()\n",
    "    \n",
    "    if only_finaldx:\n",
    "        # check the column exists first:\n",
    "        if 'has_final_diagnosis' in df_path.columns.tolist():\n",
    "            fil_finaldx_trunc = df_path.has_final_diagnosis == True\n",
    "            df_path = df_path[fil_finaldx_trunc]\n",
    "        else:\n",
    "            print('The flag *only_finaldx=True* was passed, however truncate_finaldx() has not been called. Aborting...')\n",
    "            return None\n",
    "    \n",
    "    num_reports = df_path.shape[0]\n",
    "    is_liver_biopsy_col = []\n",
    "    is_liver_biopsy_line_col = []\n",
    "    liver_biopsy_LAFD_col = []\n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = df_path.iloc[i,:].Report_Text\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "\n",
    "        is_liver_biopsy = False\n",
    "        is_liver_biopsy_line = ''\n",
    "        liver_biopsy_LAFD = -1\n",
    "\n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        for line in text_by_line:\n",
    "            lower_line = line.lower().lstrip()\n",
    "            # capture situation where a line contains liver, biopsy; note will only grab first instance then short circuit\n",
    "            if is_liver_biopsy==False and ((bool(re.search(r'\\bliver\\b|\\bhepatic\\b',lower_line)) and (\n",
    "                        bool(re.search(r\"\"\"\\bbiopsy\\b|\\bbiopsies\\b|\\blobe\\b|\\brandom\\b|\n",
    "                        |\\bnon-focal\\b|\\bnonfocal\\b|\\bnon focal\\b|\\bcore\\b|bcores\\b|\n",
    "                        |\\bspecimen\\b|\\bmass\\b|\\blesion\\b|\\btissue\\b|\\bparenchyma\\b|\n",
    "                        |\\boperation\\b|\\bsegment\\b|\\bsegments\\b|\\bexcision\\b|\\bnodule\\b|\n",
    "                        |\\bexplant\\b|\\bresection\\b|\\bhepatectomy\\b|\n",
    "                        |\\blobectomy\\b|\\bnative\\b\"\"\",lower_line)))) or \n",
    "                               ('hepatectomy' in lower_line and \n",
    "                                bool(re.search(r'\\bleft\\b|\\bright\\b|\\bpartial\\b|\\bcentral\\b',lower_line))) or (\n",
    "                                        bool(re.search(r'^\\s*[a-f][.].*\\bliver\\b',lower_line)) or\n",
    "                                        bool(re.search(r'^\\s*[a-f]/1.*\\bliver\\b',lower_line)) or\n",
    "                                        bool(re.search(r'^\\s*[a-f][.|)].*\\bliver\\b.*[(.*)]:',lower_line)) or\n",
    "                                        bool(re.search(r'.*\\bliver\\b.*[:]', lower_line)))) and not (\n",
    "                                                'colon' in lower_line or \n",
    "                                                'renal' in lower_line or\n",
    "                                                'kidney' in lower_line or\n",
    "                                                'flexure' in lower_line or\n",
    "                                                'flex' in lower_line or\n",
    "                                                'metastatic' in lower_line or\n",
    "                                                'glomerulosclerosis' in lower_line or\n",
    "                                                'lymph' in lower_line or\n",
    "                                                'brush' in lower_line or\n",
    "                                                'artery' in lower_line or\n",
    "                                                'fluid' in lower_line or\n",
    "                                                'cautery artifact' in lower_line or\n",
    "                                                'duct' in lower_line or\n",
    "                                                'clinical data' in lower_line or\n",
    "                                                'gross description' in lower_line or\n",
    "                                                'original pathologic' in lower_line or\n",
    "                                                'fna' in lower_line or\n",
    "                                                'aspiration' in lower_line or\n",
    "                                                'bile' in lower_line or\n",
    "                                                'history' in lower_line or\n",
    "                                                 lower_line.startswith('specimen:')):\n",
    "                                            #bool('liver:'==lower_line.strip())\n",
    "                \n",
    "                total_lc = sum([1 if x.islower() else 0 for x in line.split()])\n",
    "                total_uc = sum([1 if x.isupper() else 0 for x in line.split()])\n",
    "                if not ((total_lc>3) & (total_uc<3)) and total_lc<=8:\n",
    "                    is_liver_biopsy = True\n",
    "                    is_liver_biopsy_line = line\n",
    "                    liver_biopsy_LAFD = j\n",
    "                \n",
    "            j=j+1\n",
    "\n",
    "        is_liver_biopsy_col.append(is_liver_biopsy)\n",
    "        is_liver_biopsy_line_col.append(is_liver_biopsy_line)\n",
    "        liver_biopsy_LAFD_col.append(liver_biopsy_LAFD)\n",
    "\n",
    "    df_path['is_liver_biopsy'] = is_liver_biopsy_col\n",
    "    df_path['is_liver_biopsy_line'] = is_liver_biopsy_line_col\n",
    "    df_path['liver_biopsy_LAFD'] = liver_biopsy_LAFD_col\n",
    "\n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe with truncated MGH, BWH path reports')\n",
    "        pathdf['is_liver_biopsy'] = False\n",
    "        pathdf['is_liver_biopsy_line'] = ''\n",
    "        pathdf['liver_biopsy_LAFD'] = -1\n",
    "        pathdf.update(df_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh, bwh path only file\n",
    "        print('Returning entries with truncated path reports')\n",
    "        return_df = df_path\n",
    "        \n",
    "    print('Done. | Status: ' + str(df_path[df_path.is_liver_biopsy==True].shape[0]) + ' reports with likely liver biopsy, ' \n",
    "          + str(df_path[df_path.is_liver_biopsy==False].shape[0]) + ' reports likely not a liver biopsy')\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def mgh_find_note_start(pathdf, update=True, only_finaldx=True):\n",
    "    \n",
    "    if not 'is_liver_biopsy' in pathdf.columns.tolist():\n",
    "        print('Function requires running is_liver_biopsy() first (uses relative positioning of the biopsy line to call note start)')\n",
    "        return None\n",
    "    \n",
    "    print('Filtering only MGH path reports...')\n",
    "    fil_mgh = pathdf.MRN_Type == 'MGH'\n",
    "    mgh_path = pathdf[fil_mgh].copy()\n",
    "    \n",
    "    if only_finaldx:\n",
    "        # check the column exists first:\n",
    "        if 'has_final_diagnosis' in mgh_path.columns.tolist():\n",
    "            fil_finaldx_trunc = mgh_path.has_final_diagnosis == True\n",
    "            mgh_path = mgh_path[fil_finaldx_trunc]\n",
    "        else:\n",
    "            print('The flag *only_finaldx=True* was passed, however mgh_truncate_finaldx() has not been called. Aborting...')\n",
    "            return None\n",
    "    \n",
    "    num_reports = mgh_path.shape[0]\n",
    "    has_note_start_col = []\n",
    "    note_line_col = []\n",
    "    note_start_LAFD_col = []\n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = mgh_path.iloc[i,:].Report_Text\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "\n",
    "        has_note = False\n",
    "        has_note_after_biopsy = False\n",
    "        note_line = ''\n",
    "        note_start_LAFD = -1\n",
    "\n",
    "        # go line-by-line and perform some checks\n",
    "        j=0\n",
    "        for line in text_by_line:\n",
    "            lower_line = line.lower()\n",
    "            # prep for finding the first non-space word in a line\n",
    "            word_list = remove_extra_spaces(lower_line, return_as_list=True)\n",
    "            # first conditional: make sure the word list isn't empty\n",
    "            # second conditional: if we've already found note, don't look further\n",
    "            # third and beyond conditionals: that the first or second word contains note is best signature of the start of the note section\n",
    "            # the parentheses are to help it ignore catching note on a new line where it says '(see note)' or (see comment)\n",
    "            if len(word_list) > 0 and has_note_after_biopsy==False and ((('note' in word_list[0] or 'comment' in word_list[0]) and not ')' in word_list[0]) or \n",
    "                                                           (len(word_list) > 1 and (('note' in word_list[1] or 'comment' in word_list[1]) and not ')' in word_list[1]))):\n",
    "                \n",
    "                \n",
    "                # unlike other loop functions above, stipulate the 'best' note comes after the line declaring this to be a liver biopsy\n",
    "                #  but if no such line materializes, still go with the FIRST line it was seen\n",
    "                if j > mgh_path.iloc[i,:].liver_biopsy_LAFD:\n",
    "                    # stop searching, this is a good candidate\n",
    "                    has_note_after_biopsy = True\n",
    "                    has_note = True\n",
    "                    note_line = line\n",
    "                    note_start_LAFD = j\n",
    "                # this is the first encounter with a probable note line (has_note is False); keep it unless the if above is triggered with a better one\n",
    "                elif has_note == False:\n",
    "                    has_note = True\n",
    "                    note_line = line\n",
    "                    note_start_LAFD = j\n",
    "                \n",
    "            j=j+1\n",
    "\n",
    "        has_note_start_col.append(has_note)\n",
    "        note_line_col.append(note_line)\n",
    "        note_start_LAFD_col.append(note_start_LAFD)\n",
    "\n",
    "    mgh_path['has_note_start'] = has_note_start_col\n",
    "    mgh_path['note_line'] = note_line_col\n",
    "    mgh_path['note_start_LAFD'] = note_start_LAFD_col\n",
    "\n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe note starts and locations')\n",
    "        pathdf['has_note_start'] = False\n",
    "        pathdf['note_line'] = ''\n",
    "        pathdf['note_start_LAFD'] = -1\n",
    "        pathdf.update(mgh_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh path only file\n",
    "        print('Returning MGH only entries annotated note starts')\n",
    "        return_df = mgh_path\n",
    "        \n",
    "    print('Done. | Status: ' + str(mgh_path[mgh_path.has_note_start==True].shape[0]) + ' reports with an identifiable note entry, ' \n",
    "          + str(mgh_path[mgh_path.has_note_start==False].shape[0]) + ' reports without a note entry')\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "def mgh_extract_finaldx(pathdf, update=True):\n",
    "    \n",
    "    if not 'is_liver_biopsy' in pathdf.columns.tolist() and 'has_note_start' in pathdf.columns.tolist():\n",
    "        print('Function requires running mgh_is_biopsy() and mgh_find_note_start first (uses relative positioning of the biopsy line to call note start)')\n",
    "        return None\n",
    "    \n",
    "    print('Filtering only MGH path reports that are notated as liver biopsies...')\n",
    "    fil_mgh = pathdf.MRN_Type == 'MGH'\n",
    "    fil_liverbx = pathdf.is_liver_biopsy == True\n",
    "    mgh_path = pathdf[fil_mgh & fil_liverbx].copy()\n",
    "    \n",
    "    num_reports = mgh_path.shape[0]\n",
    "    has_finaldx_col = []\n",
    "    finaldx_text_col = []\n",
    "    finaldx_LAFD_col = []\n",
    "    \n",
    "    for i in range(0,num_reports):\n",
    "        # extract path report for this entry\n",
    "        report_text = mgh_path.iloc[i,:].Report_Text\n",
    "        # split by newline character\n",
    "        text_by_line = report_text.split('\\n')\n",
    "\n",
    "        has_finaldx = False\n",
    "        finaldx_text = ''\n",
    "        finaldx_LAFD = -1\n",
    "\n",
    "        # grab markers from where biopsy line is noted and where the 'note' line is\n",
    "        liverbx_LAFD = int(mgh_path.iloc[i,:].liver_biopsy_LAFD) # every entry should have a positive liver biopsy LAFD\n",
    "        note_LAFD = int(mgh_path.iloc[i,:].note_start_LAFD) # NOT every entry will have a note; that's OK\n",
    "\n",
    "        # if the order is liver biopsy line >> note, then the final diagnosis usually falls right in between\n",
    "        if note_LAFD > liverbx_LAFD:\n",
    "            finaldx_text = ' '.join(text_by_line[liverbx_LAFD+1:note_LAFD])\n",
    "            # get rid of extra spaces\n",
    "            finaldx_text = remove_extra_spaces(finaldx_text)\n",
    "            \n",
    "            has_finaldx = True\n",
    "            finaldx_LAFD = liverbx_LAFD+1\n",
    "        \n",
    "        has_finaldx_col.append(has_finaldx)\n",
    "        finaldx_text_col.append(finaldx_text)\n",
    "        finaldx_LAFD_col.append(finaldx_LAFD)\n",
    "\n",
    "    mgh_path['has_finaldx_text'] = has_finaldx_col\n",
    "    mgh_path['finaldx_text'] = finaldx_text_col\n",
    "    mgh_path['finaldx_LAFD'] = finaldx_LAFD_col\n",
    "\n",
    "    if update:\n",
    "        # re-merge with original data\n",
    "        print('Updating input path dataframe with final diagnosis (short) text')\n",
    "        pathdf['has_finaldx_text'] = False\n",
    "        pathdf['finaldx_text'] = ''\n",
    "        pathdf['finaldx_LAFD'] = -1\n",
    "        pathdf.update(mgh_path)\n",
    "        return_df = pathdf.copy()\n",
    "    else:\n",
    "        # return this mgh path only file\n",
    "        print('Returning MGH only entries passing all filters above and annotated with final diagnosis (short) text')\n",
    "        return_df = mgh_path\n",
    "        \n",
    "    print('Done. | Status: ' + str(mgh_path[mgh_path.has_finaldx_text==True].shape[0]) + ' reports with a probable final diagnosis, ' \n",
    "          + str(mgh_path[mgh_path.has_finaldx_text==False].shape[0]) + ' reports without a probable final diagnosis')\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "def remove_extra_spaces(input_as_str, return_as_list=False):\n",
    "    word_list = input_as_str.split(' ')\n",
    "    while '' in word_list: word_list.remove('')\n",
    "    \n",
    "    if return_as_list:\n",
    "        out = word_list\n",
    "    else:\n",
    "        out = ' '.join(word_list)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
